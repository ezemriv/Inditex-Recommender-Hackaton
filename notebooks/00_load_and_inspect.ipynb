{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# root path\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the project root to the Python path\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.append(ROOT)\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(ROOT, 'data')\n",
    "RAW_DATA_PATH = os.path.join(DATA_PATH, 'raw')\n",
    "\n",
    "USERS_RAW_PATH = os.path.join(RAW_DATA_PATH, 'user_batches')\n",
    "USERS_CLEAN_PATH = os.path.join(DATA_PATH, 'processed', 'users.parquet')\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'raw', 'train.csv')\n",
    "\n",
    "PRODUCTS_PATH = os.path.join(DATA_PATH, 'raw', 'products.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Data (API Call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.api_calls import fetch_all_user_ids, fetch_user_data\n",
    "\n",
    "all_ids = fetch_all_user_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 487435,\n",
       " 'values': {'country': [25], 'R': [23], 'F': [21], 'M': [25.084799999999994]}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_id = random.choice(all_ids)\n",
    "fetch_user_data(random_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all batches, merge and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.loaders import PolarsLoader\n",
    "\n",
    "loader = PolarsLoader(sampling=False, file_type='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user_batch_1.parquet: 100000 user_ids\n",
      "Processed user_batch_2.parquet: 100000 user_ids\n",
      "Processed user_batch_3.parquet: 100000 user_ids\n",
      "Processed user_batch_5.parquet: 100000 user_ids\n",
      "Processed user_batch_6.parquet: 57006 user_ids\n",
      "Processed user_batch_4.parquet: 100000 user_ids\n",
      "Final amount of users:  557006\n"
     ]
    }
   ],
   "source": [
    "down_users = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for file_name in os.listdir(USERS_RAW_PATH):\n",
    "    file_path = os.path.join(USERS_RAW_PATH, file_name)\n",
    "    \n",
    "    # Ensure the file is a parquet file before processing\n",
    "    if file_name.endswith('.parquet'):\n",
    "        data = loader.load_data(path=file_path)\n",
    "        users_ids = data['user_id']\n",
    "        down_users.extend(users_ids)  # Combine all user_ids into a single list\n",
    "        print(f\"Processed {file_name}: {len(users_ids)} user_ids\")\n",
    "\n",
    "print(\"Final amount of users: \", len(down_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user_batch_1.parquet\n",
      "Processed user_batch_2.parquet\n",
      "Processed user_batch_3.parquet\n",
      "Processed user_batch_5.parquet\n",
      "Processed user_batch_6.parquet\n",
      "Processed user_batch_4.parquet\n",
      "Final combined DataFrame saved at /home/ezemriv/other_projects/hackathon-inditex-data-recommender/data/processed/users.parquet\n",
      "\n",
      " shape: (557_006, 5)\n",
      "┌─────────┬─────┬─────┬───────────┬─────────┐\n",
      "│ country ┆ R   ┆ F   ┆ M         ┆ user_id │\n",
      "│ ---     ┆ --- ┆ --- ┆ ---       ┆ ---     │\n",
      "│ i64     ┆ i64 ┆ i64 ┆ f64       ┆ i64     │\n",
      "╞═════════╪═════╪═════╪═══════════╪═════════╡\n",
      "│ 25      ┆ 30  ┆ 0   ┆ 0.0       ┆ 430102  │\n",
      "│ 25      ┆ 177 ┆ 1   ┆ 75.9      ┆ 134198  │\n",
      "│ 25      ┆ 32  ┆ 61  ┆ 37.694058 ┆ 134207  │\n",
      "│ 25      ┆ 74  ┆ 86  ┆ 11.64094  ┆ 180365  │\n",
      "│ 25      ┆ 79  ┆ 5   ┆ 30.283333 ┆ 430101  │\n",
      "│ …       ┆ …   ┆ …   ┆ …         ┆ …       │\n",
      "│ 25      ┆ 155 ┆ 9   ┆ 17.423636 ┆ 389294  │\n",
      "│ 25      ┆ 62  ┆ 16  ┆ 45.104706 ┆ 389292  │\n",
      "│ 25      ┆ 8   ┆ 74  ┆ 36.052632 ┆ 389298  │\n",
      "│ 25      ┆ 15  ┆ 26  ┆ 20.201622 ┆ 389296  │\n",
      "│ 25      ┆ 15  ┆ 13  ┆ 93.662308 ┆ 389297  │\n",
      "└─────────┴─────┴─────┴───────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "final_df = pl.DataFrame()\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for file_name in os.listdir(USERS_RAW_PATH):\n",
    "    file_path = os.path.join(USERS_RAW_PATH, file_name)\n",
    "\n",
    "    data = loader.load_data(path=file_path)\n",
    "    final_df = pl.concat([final_df, data])\n",
    "    print(f\"Processed {file_name}\")\n",
    "\n",
    "# Save the final DataFrame\n",
    "final_df.write_parquet(USERS_CLEAN_PATH)\n",
    "\n",
    "print(f\"Final combined DataFrame saved at {USERS_CLEAN_PATH}\")\n",
    "print('\\n', final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.05634880065918\n"
     ]
    }
   ],
   "source": [
    "loader = PolarsLoader(sampling=True)\n",
    "train = loader.load_data(path=TRAIN_PATH)\n",
    "print(train.estimated_size(\"mb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>session_id</th><th>date</th><th>timestamp_local</th><th>add_to_cart</th><th>user_id</th><th>country</th><th>partnumber</th><th>device_type</th><th>pagetype</th></tr><tr><td>i64</td><td>date</td><td>datetime[μs]</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>3197684</td><td>2024-06-10</td><td>2024-06-10 20:07:40.460</td><td>1</td><td>null</td><td>34</td><td>12600</td><td>1</td><td>24.0</td></tr><tr><td>4637688</td><td>2024-06-07</td><td>2024-06-07 17:14:17.201</td><td>0</td><td>217888.0</td><td>25</td><td>26812</td><td>1</td><td>24.0</td></tr><tr><td>1770026</td><td>2024-06-07</td><td>2024-06-07 19:16:29.666</td><td>0</td><td>null</td><td>25</td><td>16138</td><td>3</td><td>24.0</td></tr><tr><td>411964</td><td>2024-06-11</td><td>2024-06-11 13:28:47.619</td><td>0</td><td>null</td><td>57</td><td>5818</td><td>1</td><td>24.0</td></tr><tr><td>1979467</td><td>2024-06-13</td><td>2024-06-13 23:38:23.669</td><td>0</td><td>208183.0</td><td>25</td><td>21999</td><td>1</td><td>24.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌────────────┬────────────┬───────────┬───────────┬───┬─────────┬───────────┬───────────┬──────────┐\n",
       "│ session_id ┆ date       ┆ timestamp ┆ add_to_ca ┆ … ┆ country ┆ partnumbe ┆ device_ty ┆ pagetype │\n",
       "│ ---        ┆ ---        ┆ _local    ┆ rt        ┆   ┆ ---     ┆ r         ┆ pe        ┆ ---      │\n",
       "│ i64        ┆ date       ┆ ---       ┆ ---       ┆   ┆ i64     ┆ ---       ┆ ---       ┆ f64      │\n",
       "│            ┆            ┆ datetime[ ┆ i64       ┆   ┆         ┆ i64       ┆ i64       ┆          │\n",
       "│            ┆            ┆ μs]       ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "╞════════════╪════════════╪═══════════╪═══════════╪═══╪═════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3197684    ┆ 2024-06-10 ┆ 2024-06-1 ┆ 1         ┆ … ┆ 34      ┆ 12600     ┆ 1         ┆ 24.0     │\n",
       "│            ┆            ┆ 0 20:07:4 ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "│            ┆            ┆ 0.460     ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "│ 4637688    ┆ 2024-06-07 ┆ 2024-06-0 ┆ 0         ┆ … ┆ 25      ┆ 26812     ┆ 1         ┆ 24.0     │\n",
       "│            ┆            ┆ 7 17:14:1 ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "│            ┆            ┆ 7.201     ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "│ 1770026    ┆ 2024-06-07 ┆ 2024-06-0 ┆ 0         ┆ … ┆ 25      ┆ 16138     ┆ 3         ┆ 24.0     │\n",
       "│            ┆            ┆ 7 19:16:2 ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "│            ┆            ┆ 9.666     ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "│ 411964     ┆ 2024-06-11 ┆ 2024-06-1 ┆ 0         ┆ … ┆ 57      ┆ 5818      ┆ 1         ┆ 24.0     │\n",
       "│            ┆            ┆ 1 13:28:4 ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "│            ┆            ┆ 7.619     ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "│ 1979467    ┆ 2024-06-13 ┆ 2024-06-1 ┆ 0         ┆ … ┆ 25      ┆ 21999     ┆ 1         ┆ 24.0     │\n",
       "│            ┆            ┆ 3 23:38:2 ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "│            ┆            ┆ 3.669     ┆           ┆   ┆         ┆           ┆           ┆          │\n",
       "└────────────┴────────────┴───────────┴───────────┴───┴─────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>session_id</th><th>date</th><th>timestamp_local</th><th>add_to_cart</th><th>user_id</th><th>country</th><th>partnumber</th><th>device_type</th><th>pagetype</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>852533</td><td>0</td><td>0</td><td>0</td><td>15</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 9)\n",
       "┌────────────┬──────┬─────────────┬─────────────┬───┬─────────┬────────────┬────────────┬──────────┐\n",
       "│ session_id ┆ date ┆ timestamp_l ┆ add_to_cart ┆ … ┆ country ┆ partnumber ┆ device_typ ┆ pagetype │\n",
       "│ ---        ┆ ---  ┆ ocal        ┆ ---         ┆   ┆ ---     ┆ ---        ┆ e          ┆ ---      │\n",
       "│ u32        ┆ u32  ┆ ---         ┆ u32         ┆   ┆ u32     ┆ u32        ┆ ---        ┆ u32      │\n",
       "│            ┆      ┆ u32         ┆             ┆   ┆         ┆            ┆ u32        ┆          │\n",
       "╞════════════╪══════╪═════════════╪═════════════╪═══╪═════════╪════════════╪════════════╪══════════╡\n",
       "│ 0          ┆ 0    ┆ 0           ┆ 0           ┆ … ┆ 0       ┆ 0          ┆ 0          ┆ 15       │\n",
       "└────────────┴──────┴─────────────┴─────────────┴───┴─────────┴────────────┴────────────┴──────────┘"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique counts for session_id: 95364\n",
      "\n",
      "Unique counts for date: 15\n",
      "\n",
      "Unique counts for timestamp_local: 999488\n",
      "\n",
      "Unique counts for add_to_cart: 2\n",
      "\n",
      "Unique counts for user_id: 10786\n",
      "\n",
      "Unique counts for country: 4\n",
      "\n",
      "Unique counts for partnumber: 26380\n",
      "\n",
      "Unique counts for device_type: 3\n",
      "\n",
      "Unique counts for pagetype: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get value counts for all columns\n",
    "value_counts = {col: train[col].n_unique() for col in train.columns}\n",
    "\n",
    "# Print value counts for each column\n",
    "for col, counts in value_counts.items():\n",
    "    print(f\"Unique counts for {col}: {counts}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check distribution of variables so I can downcast some\n",
    "# df = train.to_pandas()\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.033950805664062\n"
     ]
    }
   ],
   "source": [
    "train = train.with_columns([\n",
    "    pl.col(\"session_id\").cast(pl.UInt32),       # Downcast to unsigned 32-bit integer\n",
    "    pl.col(\"add_to_cart\").cast(pl.UInt8),       # Downcast to unsigned 8-bit integer\n",
    "    pl.col(\"user_id\").cast(pl.UInt32),         # Downcast to 32-bit float\n",
    "    pl.col(\"country\").cast(pl.UInt8),     # Convert to categorical\n",
    "    pl.col(\"partnumber\").cast(pl.UInt16),       # Downcast to unsigned 32-bit integer\n",
    "    pl.col(\"device_type\").cast(pl.UInt8),       # Downcast to unsigned 8-bit integer\n",
    "    pl.col(\"pagetype\").cast(pl.UInt8),        # Downcast to 32-bit float\n",
    "])\n",
    "\n",
    "print(train.estimated_size(\"mb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caster(df, train=True):\n",
    "    print(f\"Initial Size: {df.estimated_size('mb')}\")\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col(\"session_id\").cast(pl.UInt32),\n",
    "        pl.col(\"user_id\").cast(pl.UInt32),\n",
    "        pl.col(\"country\").cast(pl.UInt8),\n",
    "        pl.col(\"partnumber\").cast(pl.UInt16),\n",
    "        pl.col(\"device_type\").cast(pl.UInt8),\n",
    "        pl.col(\"pagetype\").cast(pl.UInt8),\n",
    "    ])\n",
    "\n",
    "    if train:\n",
    "        df = df.with_columns([\n",
    "                pl.col(\"add_to_cart\").cast(pl.UInt8)])\n",
    "\n",
    "    print(f\"Final Size: {df.estimated_size('mb')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Size: 25.033950805664062\n",
      "Final Size: 25.033950805664062\n"
     ]
    }
   ],
   "source": [
    "caster(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast down and save as parquet (also test)\n",
    "\n",
    "Done with script on ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  discount                                          embedding  partnumber  \\\n",
      "0        0  [-0.13401361, -0.1200429, -0.016117405, -0.167...       32776   \n",
      "1        0  [-0.0949274, -0.107294075, -0.16559914, -0.174...       41431   \n",
      "2        0  [-0.12904441, -0.07724628, -0.09799071, -0.164...       39419   \n",
      "3        1  [-0.12783332, -0.133868, -0.10101265, -0.18888...       36087   \n",
      "4        1  [-0.14092924, -0.1258284, -0.10809927, -0.1765...       34132   \n",
      "\n",
      "   color_id  cod_section  family  \n",
      "0        85          4.0      73  \n",
      "1       135          4.0      73  \n",
      "2       339          4.0      73  \n",
      "3       135          4.0      73  \n",
      "4         3          4.0      73  \n",
      "(43692, 6)\n"
     ]
    }
   ],
   "source": [
    "prods = pd.read_pickle(PRODUCTS_PATH)\n",
    "print(prods.head())\n",
    "print(prods.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
